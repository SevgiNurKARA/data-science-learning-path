{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression - Proje: Müşteri Churn Tahmini\n",
        "\n",
        "Bu proje, bir telekomünikasyon şirketinin müşteri kaybını (churn) tahmin etmek için Logistic Regression kullanır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proje Adımları\n",
        "\n",
        "1. Veri Keşfi ve Analiz\n",
        "2. Veri Ön İşleme\n",
        "3. Feature Engineering\n",
        "4. Model Eğitimi\n",
        "5. Model Değerlendirme\n",
        "6. Sonuçlar ve Öneriler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Kütüphaneler yüklendi!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Veri Yükleme ve Keşif\n",
        "\n",
        "Veri setini yükleyin ve temel istatistikleri inceleyin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Veri setini yükleyin (örnek: kaggle'dan telecom churn dataset)\n",
        "# df = pd.read_csv('telecom_churn.csv')\n",
        "\n",
        "# VEYA örnek veri oluşturun\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, \n",
        "                           n_redundant=5, n_clusters_per_class=1, \n",
        "                           random_state=42, class_sep=0.8)\n",
        "\n",
        "# Örnek feature isimleri\n",
        "feature_names = [f'Feature_{i+1}' for i in range(20)]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['Churn'] = y\n",
        "\n",
        "print(f\"Veri seti boyutu: {df.shape}\")\n",
        "print(f\"\\\\nSınıf dağılımı:\\\\n{df['Churn'].value_counts()}\")\n",
        "print(f\"\\\\nEksik değerler:\\\\n{df.isnull().sum().sum()}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Veri Ön İşleme ve Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X ve y'yi ayır\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Eğitim seti boyutu: {X_train_scaled.shape}\")\n",
        "print(f\"Test seti boyutu: {X_test_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Eğitimi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model oluştur ve eğit\n",
        "model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "# Tahmin\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Değerlendirme\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\\\nConfusion Matrix:\\\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\\\nClassification Report:\\\\n{classification_report(y_test, y_pred)}\")\n",
        "\n",
        "# ROC-AUC\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"\\\\nROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Importance\n",
        "\n",
        "Model katsayılarını analiz ederek en önemli feature'ları belirleyin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (katsayıların mutlak değerleri)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': model.coef_[0],\n",
        "    'Abs_Coefficient': np.abs(model.coef_[0])\n",
        "}).sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"En önemli 10 feature:\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# Görselleştir\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance.head(10), x='Abs_Coefficient', y='Feature')\n",
        "plt.title('Top 10 Feature Importance')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sonuçlar ve Öneriler\n",
        "\n",
        "Model performansını özetleyin ve iş değeri sağlayacak öneriler sunun.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"PROJE ÖZETİ\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\\\nModel Accuracy: {accuracy:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"\\\\nEn önemli 5 feature:\")\n",
        "for idx, row in feature_importance.head(5).iterrows():\n",
        "    print(f\"  - {row['Feature']}: {row['Coefficient']:.4f}\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\" * 50)\n",
        "print(\"ÖNERİLER:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"1. Model performansını artırmak için feature engineering yapılabilir\")\n",
        "print(\"2. Dengesiz veri seti için SMOTE veya diğer teknikler kullanılabilir\")\n",
        "print(\"3. Hyperparameter tuning ile model optimize edilebilir\")\n",
        "print(\"4. Ensemble methods ile daha iyi sonuçlar elde edilebilir\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
