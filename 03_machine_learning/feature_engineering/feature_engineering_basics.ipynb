{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering - Temel Kavramlar\n",
        "\n",
        "Bu notebook, feature engineering tekniklerini ve uygulamalarını içerir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Feature Scaling\n",
        "\n",
        "Farklı scaling yöntemlerini karşılaştırma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Örnek veri\n",
        "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
        "df = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(5)])\n",
        "\n",
        "# Farklı scaling yöntemleri\n",
        "scalers = {\n",
        "    'Original': None,\n",
        "    'StandardScaler': StandardScaler(),\n",
        "    'MinMaxScaler': MinMaxScaler(),\n",
        "    'RobustScaler': RobustScaler()\n",
        "}\n",
        "\n",
        "scaled_data = {}\n",
        "for name, scaler in scalers.items():\n",
        "    if scaler is None:\n",
        "        scaled_data[name] = df\n",
        "    else:\n",
        "        scaled_data[name] = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# İstatistikleri karşılaştır\n",
        "print(\"Feature Scaling Karşılaştırması:\")\n",
        "for name, data in scaled_data.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Mean: {data.mean().values}\")\n",
        "    print(f\"  Std:  {data.std().values}\")\n",
        "    print(f\"  Min:  {data.min().values}\")\n",
        "    print(f\"  Max:  {data.max().values}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Selection\n",
        "\n",
        "En önemli feature'ları seçme teknikleri.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. SelectKBest (Univariate Selection)\n",
        "selector_kbest = SelectKBest(score_func=f_classif, k=3)\n",
        "X_train_selected = selector_kbest.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector_kbest.transform(X_test)\n",
        "\n",
        "selected_features = selector_kbest.get_support()\n",
        "print(\"SelectKBest ile seçilen feature'lar:\")\n",
        "print([f'Feature_{i+1}' for i, selected in enumerate(selected_features) if selected])\n",
        "\n",
        "# 2. RFE (Recursive Feature Elimination)\n",
        "rfe = RFE(estimator=RandomForestClassifier(n_estimators=50, random_state=42), n_features_to_select=3)\n",
        "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "rfe_features = rfe.get_support()\n",
        "print(\"\\nRFE ile seçilen feature'lar:\")\n",
        "print([f'Feature_{i+1}' for i, selected in enumerate(rfe_features) if selected])\n",
        "\n",
        "# 3. Feature Importance (Tree-based)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': [f'Feature_{i+1}' for i in range(len(rf.feature_importances_))],\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance (Top 3):\")\n",
        "print(feature_importance.head(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Encoding Teknikleri\n",
        "\n",
        "Kategorik değişkenleri encode etme yöntemleri.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Örnek kategorik veri\n",
        "df_cat = pd.DataFrame({\n",
        "    'Category': ['A', 'B', 'C', 'A', 'B', 'C', 'A'],\n",
        "    'Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Small']\n",
        "})\n",
        "\n",
        "# 1. Label Encoding\n",
        "le = LabelEncoder()\n",
        "df_cat['Category_LabelEncoded'] = le.fit_transform(df_cat['Category'])\n",
        "print(\"Label Encoding:\")\n",
        "print(df_cat[['Category', 'Category_LabelEncoded']].head())\n",
        "\n",
        "# 2. One-Hot Encoding\n",
        "df_onehot = pd.get_dummies(df_cat[['Category', 'Size']], prefix=['Cat', 'Size'])\n",
        "print(\"\\nOne-Hot Encoding:\")\n",
        "print(df_onehot.head())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
